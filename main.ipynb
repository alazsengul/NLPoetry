{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLPoetry\n",
    "\n",
    "### Generating poems using word embeddings from specified poets\n",
    "#### Inspired by [Benjamín Durán's AI poetry](https://towardsdatascience.com/creating-a-poems-generator-using-word-embeddings-bcc43248de4f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanramos/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: DeprecationWarning: AppURLopener style of invoking requests is deprecated. Use newer urlopen functions/methods\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john-keats-poems\n",
      "A Dream, After Reading Dante's Episode...\n",
      "Addressed To Haydon\n",
      "Answer To A Sonnet By J.H.Reynolds\n",
      "Bards of Passion and of Mirth,...\n",
      "Bright Star\n",
      "Endymion: Book I. A Thing of Beauty is a Joy Forever\n",
      "Endymion: Book II\n",
      "Endymion: Book III\n",
      "Endymion: Book IV\n",
      "Epistle To My Brother George\n",
      "Fancy\n",
      "Fill For Me A Brimming Bowl\n",
      "Fragment of an Ode to Maia\n",
      "Give Me Women, Wine, and Snuff\n",
      "Happy Is England\n",
      "His Last Sonnet\n",
      "Hither, Hither, Love\n",
      "How Many Bards Gild The Lapses Of Time!\n",
      "Hymn To Apollo\n",
      "Hyperion\n",
      "I Stood tip-toe upon a little hill\n",
      "If by Dull Rhymes our English must be Chain'd\n",
      "In Drear-Nighted December\n",
      "Isabella or The Pot of Basil\n",
      "Keen, Fitful Gusts are Whisp'ring Here and There\n",
      "La Belle Dame Sans Merci\n",
      "Lamia\n",
      "Lines\n",
      "Lines on The Mermaid Tavern\n",
      "Meg Merrilies\n",
      "O Blush Not So!\n",
      "O Solitude! If I Must With Thee Dwell\n",
      "Ode On A Grecian Urn\n",
      "Ode On Indolence\n",
      "Ode on Melancholy\n",
      "Ode To A Nightingale\n",
      "Ode to Apollo\n",
      "Ode To Autumn\n",
      "Ode to Fanny\n",
      "Ode To Psyche\n",
      "On Fame\n",
      "On First Looking Into Chapman's Homer\n",
      "On Leaving Some Friends At An Early Hour\n",
      "On Seeing the Elgin Marbles for the First Time\n",
      "On Sitting Down to Read King Lear Once Again\n",
      "On the Grasshopper and Cricket\n",
      "On the Sea\n",
      "Robin Hood\n",
      "Sleep And Poetry\n",
      "The Day Is Gone, And All Its Sweets Are Gone\n",
      "The Eve of Saint Mark\n",
      "The Eve Of St. Agnes\n",
      "The Human Seasons\n",
      "Think Of It Not, Sweet One\n",
      "This Living Hand\n",
      "To\n",
      "To A Friend Who Sent Me Some Roses\n",
      "To A Young Lady Who Sent Me A Laurel Crown\n",
      "To Ailsa Rock\n",
      "To Autumn\n",
      "To Byron\n",
      "To Fanny\n",
      "To G.A.W.\n",
      "To Haydon\n",
      "To Homer\n",
      "To Hope\n",
      "To John Hamilton Reynolds\n",
      "To Mrs Reynolds' Cat\n",
      "To My Brother George\n",
      "To My Brothers\n",
      "To one who has been long in city pent\n",
      "To Sleep\n",
      "To Solitude\n",
      "To the Nile\n",
      "To—\n",
      "When I Have Fears\n",
      "Where Be Ye Going, You Devon Maid?\n",
      "Where's the Poet?\n",
      "Why did I laugh tonight? No voice will tell\n",
      "Written Before Re-Reading King Lear\n",
      "Written on a Blank Space\n",
      "Written on a Summer Evening\n",
      "Written on the Day that Mr Leigh Hunt Left Prison\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/Users/jordanramos/Documents/NLPoetry/john_keats_poems.csv' does not exist: b'/Users/jordanramos/Documents/NLPoetry/john_keats_poems.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-170-69898fb7fa36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentences/sentences_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mpoem_parsing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-170-69898fb7fa36>\u001b[0m in \u001b[0;36mpoem_parsing\u001b[0;34m(file, split)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpoem_parsing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mnum_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'doc_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0mskip_blank_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_blank_lines\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[0;32m--> 685\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m                     )\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                     \u001b[0;31m# Annoying corner case for not warning about\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m                     \u001b[0;31m# conflicts between dialect and delimiter parameter.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0;31m# Refer to the outer \"_read_\" function for more info.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m             \u001b[0mconverters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;31m# Converting values to NA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0mkeep_default_na\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"keep_default_na\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mknown_cats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m                 \u001b[0;31m# TODO: this is for consistency with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m                 \u001b[0;31m# c-parser which parses all categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m                 \u001b[0;31m# as strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/Users/jordanramos/Documents/NLPoetry/john_keats_poems.csv' does not exist: b'/Users/jordanramos/Documents/NLPoetry/john_keats_poems.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "writer_list = {\n",
    "    \"Maya Angelou\" : \"maya-angelou-poems\",\n",
    "    \"Langston Hughes\" : \"langston-hughes-poems\",\n",
    "    \"Pablo Neruda\" : \"pablo-neruda-poems\",\n",
    "    \"William Wordsworth\" : \"william-wordsworth-poems\",\n",
    "    \"William Shakespeare\" : \"william-shakespeare-poems\",\n",
    "    \"Charles Bukowski\" : \"charles-bukowski-poems\",\n",
    "    \"Robert Burns\" : \"robert-burns-poems\",\n",
    "    \"Rabindranath Tagore\" : \"rabindranath-tagore-poems\",\n",
    "    \"Rudyard Kipling\" : \"rudyard-kipling-poems\",\n",
    "    \"Robert Frost\" : \"robert-frost-poems\",\n",
    "    \"Edgar Allan Poe\" : \"edgar-allan-poe-poems\",\n",
    "    \"Sylvia Plath\" : \"sylvia-plath-poems\",\n",
    "    \"Walt Whitman\" : \"walt-whitman-poems\",\n",
    "    \"William Blake\" : \"william-blake-poems\",\n",
    "    \"Dylan Thomas\" : \"dylan-thomas-poems\",\n",
    "    \"John Keats\" : \"john-keats-poems\",\n",
    "    \"Wilfred Owen\" : \"wilfred-owen-poems\",\n",
    "    \"Roald Dahl\" : \"roald-dahl-poems\"\n",
    "}\n",
    "\n",
    "class AppURLopener(urllib.request.FancyURLopener): \n",
    "    version = \"Mozilla/5.0\" \n",
    "opener = AppURLopener()\n",
    "writer = random.choice(list(writer_list.values()))\n",
    "print(writer)\n",
    "data = opener.open('https://mypoeticside.com/poets/' + writer).read().decode()\n",
    "\n",
    "poem_list = bs(data, 'html.parser').find(class_=\"list-poems\")\n",
    "results = [\"https:\"+link.get('href') for link in poem_list.findAll('a')]\n",
    "\n",
    "titles = []\n",
    "content = []\n",
    "\n",
    "for page in results:\n",
    "     data = opener.open(page).read().decode()\n",
    "     soup = bs(data, 'html.parser')\n",
    "    \n",
    "     poem_title = soup.find(class_='title-poem')\n",
    "     poem_content = soup.find(class_='poem-entry')\n",
    "    \n",
    "     titles.append(poem_title.getText())\n",
    "     print(poem_title.getText())\n",
    "    \n",
    "     content.append(poem_content.find('p').getText())\n",
    "     \n",
    " #saves to a .csv file all the poems   \n",
    "poems = pd.DataFrame({'title' : titles, 'text' : content})\n",
    "csv_name = (writer + '.csv').replace(\"-\", \"_\")\n",
    "poems.to_csv(csv_name)\n",
    "\n",
    "def poem_parsing(file, split = r\"\\n\"):\n",
    "    docs = pd.read_csv(os.getcwd() + \"/\" + file)\n",
    "    num_docs = docs.shape[0]\n",
    "    sentences = pd.DataFrame(columns=['doc_id', 'sentence'])\n",
    "    \n",
    "    for i in range(num_docs):\n",
    "        poem = docs.text[i].lower()\n",
    "        \n",
    "        change_chars = {\n",
    "            '?«' :  '«', \n",
    "            '(' :  '', \n",
    "            ')' : '', \n",
    "            ':' : ',', \n",
    "            '.' : ',', \n",
    "            ',,,' : ',', \n",
    "            '\"' : ''\n",
    "        }\n",
    "        \n",
    "        for x, y in change_chars.items():\n",
    "            poem = poem.replace(x,y)\n",
    "        \n",
    "        s = re.split(split, poem)\n",
    "        doc_id = [i] * len(s)\n",
    "        sen_dic = {'doc_id' : doc_id, 'sentence' : s}\n",
    "        \n",
    "        sentences = sentences.append(pd.DataFrame(sen_dic))\n",
    "    print(sentences)\n",
    "        \n",
    "    sentences = sentences[sentences.sentence != '']\n",
    "    sentences.reset_index(drop=True, inplace=True)  \n",
    "    sentences.to_csv(\"sentences_\" + file)\n",
    "    \n",
    "poem_parsing(csv_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poem_generator(file, word, num_sen=12):\n",
    "    spacy_nlp = spacy.load(\"en\")\n",
    "    subject = spacy_nlp(word)\n",
    "    sentences = pd.read_csv(os.getcwd() +'/'+ file).fillna(\"\")\n",
    "    poem_id = int()\n",
    "    poem_lst = []\n",
    "    \n",
    "    for i in range(num_sen):\n",
    "        rand = np.random.randint(0, sentences.shape[0], size = 30)\n",
    "        docs = spacy_nlp.pipe(list(sentences.sentence.iloc[rand]))\n",
    "        \n",
    "        similarities = []\n",
    "        for s in docs:\n",
    "            similarities.append(spacy_nlp(word).similarity(s))\n",
    "            \n",
    "        s_dict = {\n",
    "            'similarity' : similarities,\n",
    "            'doc_id' : sentences.doc_id.iloc[rand]\n",
    "        }\n",
    "        \n",
    "        df_sim = pd.DataFrame(s_dict, index=rand)\n",
    "        df_sim = df_sim[df_sim.doc_id != poem_id]\n",
    "        df_sim.sort_values(by='similarity', inplace=True, ascending=False)\n",
    "        \n",
    "        s = sentences.sentence[df_sim.index[0]]\n",
    "        \n",
    "        change_chars = {\n",
    "            '\\n' :  '', \n",
    "            '\\r' :  '', \n",
    "        }\n",
    "        \n",
    "        for x, y in change_chars.items():\n",
    "            s = s.replace(x, y)\n",
    "        \n",
    "        poem_lst.append(s)\n",
    "        poem_id = df_sim.doc_id.iloc[0]\n",
    "        subject = spacy_nlp(s)\n",
    "    \n",
    "    poem = (\"\\n\".join(poem_lst))\n",
    "    return poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poem_format(text):\n",
    "    return (text[:1].upper() + text[1:])[:-1] + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanramos/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unspoken to\n",
      "my plight is just as terrible,\n",
      "disgust,\n",
      "at their best, there is gentleness in humanity,\n",
      "ashamed of my sentimentality and\n",
      "telling you to forget the dead armies and the loves\n",
      "whose life had\n",
      "sadness takes me all over\n",
      "and the sadness becomes so great\n",
      "this is not a god-damned\n",
      "from her! her precious wallace! christ! what a mess! he claimed he loved me,\n",
      "letting the warmth o.\n"
     ]
    }
   ],
   "source": [
    "sentences_csv = \"sentences/sentences_\" + csv_name\n",
    "\n",
    "poem = poem_generator(file = sentences_csv, word='valor')\n",
    "poem = poem_format(poem)\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
