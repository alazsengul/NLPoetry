{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLPoetry\n",
    "\n",
    "### Generating poems using word embeddings from specified poets\n",
    "#### Inspired by [Benjamín Durán's AI poetry](https://towardsdatascience.com/creating-a-poems-generator-using-word-embeddings-bcc43248de4f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanramos/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: DeprecationWarning: AppURLopener style of invoking requests is deprecated. Use newer urlopen functions/methods\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robert-burns-poems\n",
      "A Bard's Epitaph\n",
      "A Bottle And Friend\n",
      "A Dedication\n",
      "A Dream\n",
      "A Fiddler In The North\n",
      "A Man's a Man for A' That\n",
      "A Poets Welcome to His Love-Begotten Daughter\n",
      "A Red, Red Rose\n",
      "A Winter Night\n",
      "Address To A Haggis\n",
      "Address to the Devil\n",
      "Address To The Tooth-Ache\n",
      "Address to the Unco Guid\n",
      "Ae Fond Kiss\n",
      "Afton Water\n",
      "Again Rejoicing Nature Sees\n",
      "Ah, Woe Is Me, My Mother Dear\n",
      "Anna, thy Charms\n",
      "Auld Lang Syne\n",
      "Bonie Lesley\n",
      "Bonie Peggy Alison\n",
      "Ca' the Yowes to the Knowes\n",
      "Comin Thro' The Rye\n",
      "Craigieburn Wood\n",
      "Despondency -- An Ode\n",
      "Duncan Gray\n",
      "Epistle to a Young Friend\n",
      "Epistle to J. Lapraik (excerpt)\n",
      "Epitaph on Holy Willie\n",
      "Fareweel To A'Our Scottish Fame\n",
      "First Six Verses Of The Ninetieth Psalm Versified, The\n",
      "For A' That\n",
      "From Lines to William Simson\n",
      "Go Fetch to Me a Pint\n",
      "Green Grow The Rashes\n",
      "Halloween\n",
      "Handsome Nell\n",
      "Here's A Health To Them That's Awa\n",
      "Here's To Thy Health\n",
      "Highland Mary\n",
      "Holy Willie's Prayer\n",
      "I Dream'd I Lay\n",
      "In The Character Of A Ruined Farmer\n",
      "It Was A' For Our Rightfu' King\n",
      "John Anderson, my Jo\n",
      "John Barleycorn: A Ballad\n",
      "Lament For Culloden\n",
      "Lament of Mary, Queen of Scots, On the Approach of Spring\n",
      "Last May a Braw Wooer\n",
      "Lines on the Fall of Fyers Near Loch Ness\n",
      "Love in the Guise of Friendship\n",
      "Mary Morison\n",
      "Montgomerie's Peggy\n",
      "My Heart's In The Highlands\n",
      "My Highland Lassie, O\n",
      "My Love, She's But a Lassie Yet\n",
      "My Nannie, O\n",
      "Now Spring Has Clad The Grove In Green\n",
      "O Thou Dread Power\n",
      "O Tibbie, I Hae Seen The Day\n",
      "O, Were My Love Yon Lilac Fair\n",
      "Of A' the Airts\n",
      "Oh Wert Thou In The Cauld Blast\n",
      "On A Bank Of Flowers\n",
      "Paraphrase Of The First Psalm\n",
      "Peggy\n",
      "Poor Mailie's Elegy\n",
      "Robert Bruce's March to Bannockburn\n",
      "Scotch Drink\n",
      "Scots, Wha Hae Wi' Wallace Bled\n",
      "Tam Glen\n",
      "Tam O' Shanter\n",
      "The Auld Farmer's New-Year-Morning Salutation to His Auld Mare , Maggie\n",
      "The Banks O' Doon\n",
      "The Battle Of Sherramuir\n",
      "The Birks Of Aberfeldy\n",
      "The Bonie Wee Thing\n",
      "The Cotter's Saturday Night\n",
      "The Death and Dying Words of Poor Mailie\n",
      "The Gloomy Night Is Gath'ring Fast\n",
      "The Holy Fair\n",
      "The Lass Of Cessnock Banks\n",
      "The Lass That Made the Bed to Me\n",
      "The Lover’s Morning Salute to his Mistress\n",
      "The Ploughman's Life\n",
      "The Rigs O' Barley\n",
      "The Ronalds Of The Bennals\n",
      "The Tarbolton Lasses\n",
      "The Tear-drop\n",
      "The Wounded Hare\n",
      "Thou Lingering Star\n",
      "Tibbie Dunbar\n",
      "To A Kiss\n",
      "To A Louse\n",
      "To a Mountain Daisy\n",
      "To a Mouse, (The best laid schemes o' Mice an' Men)\n",
      "To Miss Jessie Lewars\n",
      "To The Wood-Lark\n",
      "Tragic Fragment\n",
      "Under The Pressure Of Violent Anguish\n",
      "Up in the Morning Early\n",
      "Verses to Clarinda\n",
      "Winter: A Dirge\n",
      "Ye Banks And Braes O'Bonnie Doon\n",
      "   doc_id                                     sentence\n",
      "0       0             is there a whim-inspired fool,\\r\n",
      "1       0  owre fast for thought, owre hot for rule,\\r\n",
      "2       0   owre blate to seek, owre proud to snool,\\r\n",
      "3       0                         let him draw near;\\r\n",
      "4       0       and owre this grassy heap sing dool,\\r\n",
      "..    ...                                          ...\n",
      "19    103                                           \\r\n",
      "20    103          wi' lightsome heart i pu'd a rose\\r\n",
      "21    103                  frae aff its thorny tree;\\r\n",
      "22    103          and my fause luver staw the rose,\\r\n",
      "23    103                   but left the thorn wi' me,\n",
      "\n",
      "[5093 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "writer_list = {\n",
    "    \"Maya Angelou\" : \"maya-angelou-poems\",\n",
    "    \"Langston Hughes\" : \"langston-hughes-poems\",\n",
    "    \"Pablo Neruda\" : \"pablo-neruda-poems\",\n",
    "    \"William Wordsworth\" : \"william-wordsworth-poems\",\n",
    "    \"William Shakespeare\" : \"william-shakespeare-poems\",\n",
    "    \"Charles Bukowski\" : \"charles-bukowski-poems\",\n",
    "    \"Robert Burns\" : \"robert-burns-poems\",\n",
    "    \"Rabindranath Tagore\" : \"rabindranath-tagore-poems\",\n",
    "    \"Rudyard Kipling\" : \"rudyard-kipling-poems\",\n",
    "    \"Robert Frost\" : \"robert-frost-poems\",\n",
    "    \"Edgar Allan Poe\" : \"edgar-allan-poe-poems\",\n",
    "    \"Sylvia Plath\" : \"sylvia-plath-poems\",\n",
    "    \"Walt Whitman\" : \"walt-whitman-poems\",\n",
    "    \"William Blake\" : \"william-blake-poems\",\n",
    "    \"Dylan Thomas\" : \"dylan-thomas-poems\",\n",
    "    \"John Keats\" : \"john-keats-poems\",\n",
    "    \"Wilfred Owen\" : \"wilfred-owen-poems\",\n",
    "    \"Roald Dahl\" : \"roald-dahl-poems\"\n",
    "}\n",
    "\n",
    "class AppURLopener(urllib.request.FancyURLopener): \n",
    "    version = \"Mozilla/5.0\" \n",
    "opener = AppURLopener()\n",
    "writer = random.choice(list(writer_list.values()))\n",
    "print(writer)\n",
    "data = opener.open('https://mypoeticside.com/poets/' + writer).read().decode()\n",
    "\n",
    "poem_list = bs(data, 'html.parser').find(class_=\"list-poems\")\n",
    "results = [\"https:\"+link.get('href') for link in poem_list.findAll('a')]\n",
    "\n",
    "titles = []\n",
    "content = []\n",
    "\n",
    "for page in results:\n",
    "     data = opener.open(page).read().decode()\n",
    "     soup = bs(data, 'html.parser')\n",
    "    \n",
    "     poem_title = soup.find(class_='title-poem')\n",
    "     poem_content = soup.find(class_='poem-entry')\n",
    "    \n",
    "     titles.append(poem_title.getText())\n",
    "     print(poem_title.getText())\n",
    "    \n",
    "     content.append(poem_content.find('p').getText())\n",
    "     \n",
    " #saves to a .csv file all the poems   \n",
    "poems = pd.DataFrame({'title' : titles, 'text' : content})\n",
    "csv_name = (writer + '.csv').replace(\"-\", \"_\")\n",
    "poems.to_csv(csv_name)\n",
    "\n",
    "def poem_parsing(file, split = r\"\\n\"):\n",
    "    docs = pd.read_csv(os.getcwd() + \"/\" + file)\n",
    "    num_docs = docs.shape[0]\n",
    "    sentences = pd.DataFrame(columns=['doc_id', 'sentence'])\n",
    "    \n",
    "    for i in range(num_docs):\n",
    "        poem = docs.text[i].lower()\n",
    "        \n",
    "        change_chars = {\n",
    "            '?«' :  '«', \n",
    "            '(' :  '', \n",
    "            ')' : '', \n",
    "            ':' : ',', \n",
    "            '.' : ',', \n",
    "            ',,,' : ',', \n",
    "            '\"' : ''\n",
    "        }\n",
    "        \n",
    "        for x, y in change_chars.items():\n",
    "            poem = poem.replace(x,y)\n",
    "        \n",
    "        s = re.split(split, poem)\n",
    "        doc_id = [i] * len(s)\n",
    "        sen_dic = {'doc_id' : doc_id, 'sentence' : s}\n",
    "        \n",
    "        sentences = sentences.append(pd.DataFrame(sen_dic))\n",
    "    print(sentences)\n",
    "        \n",
    "    sentences = sentences[sentences.sentence != '']\n",
    "    sentences.reset_index(drop=True, inplace=True)  \n",
    "    sentences.to_csv(\"sentences_\" + file)\n",
    "    \n",
    "poem_parsing(csv_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poem_generator(file, word, num_sen=4):\n",
    "    spacy_nlp = spacy.load(\"en\")\n",
    "    subject = spacy_nlp(word)\n",
    "    sentences = pd.read_csv(os.getcwd() +'/'+ file).fillna(\"\")\n",
    "    poem_id = int()\n",
    "    poem_lst = []\n",
    "    \n",
    "    for i in range(num_sen):\n",
    "        rand = np.random.randint(0, sentences.shape[0], size = 30)\n",
    "        docs = spacy_nlp.pipe(list(sentences.sentence.iloc[rand]))\n",
    "        \n",
    "        similarities = []\n",
    "        for s in docs:\n",
    "            similarities.append(spacy_nlp(word).similarity(s))\n",
    "            \n",
    "        s_dict = {\n",
    "            'similarity' : similarities,\n",
    "            'doc_id' : sentences.doc_id.iloc[rand]\n",
    "        }\n",
    "        \n",
    "        df_sim = pd.DataFrame(s_dict, index=rand)\n",
    "        df_sim = df_sim[df_sim.doc_id != poem_id]\n",
    "        df_sim.sort_values(by='similarity', inplace=True, ascending=False)\n",
    "        \n",
    "        s = sentences.sentence[df_sim.index[0]]\n",
    "        \n",
    "        change_chars = {\n",
    "            '\\n' :  '', \n",
    "            '\\r' :  '', \n",
    "        }\n",
    "        \n",
    "        for x, y in change_chars.items():\n",
    "            s = s.replace(x, y)\n",
    "        \n",
    "        poem_lst.append(s)\n",
    "        poem_id = df_sim.doc_id.iloc[0]\n",
    "        subject = spacy_nlp(s)\n",
    "    \n",
    "    poem = (\"\\n\".join(poem_lst))\n",
    "    return poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poem_format(text):\n",
    "    return (text[:1].upper() + text[1:])[:-1] + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanramos/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My fate will scarce bestow,\n",
      "they've lost some gallant gentlemen,\n",
      "dearest tie of young connections,\n",
      "but with humility and aw.\n"
     ]
    }
   ],
   "source": [
    "sentences_csv = \"sentences_\" + csv_name\n",
    "\n",
    "poem = poem_generator(file = sentences_csv, word='valor')\n",
    "poem = poem_format(poem)\n",
    "print(poem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
